{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set : 50000, Test data Set : 10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "sess=tf.Session()\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        data_dic = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i==1:\n",
    "            train_data = data_dic['data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dic['data']))\n",
    "        train_labels += data_dic['labels']\n",
    "    test_data_dic = unpickle(data_dir + \"/test_batch\")\n",
    "    test_data = test_data_dic['data']\n",
    "    test_labels = test_data_dic['labels']\n",
    "    \n",
    "    train_data = train_data.reshape((len(train_data), 3, 32, 32))\n",
    "    train_data = np.rollaxis(train_data, 1, 4)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    test_data = test_data.reshape((len(test_data), 3, 32, 32))\n",
    "    test_data = np.rollaxis(test_data, 1, 4)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "data_dir = 'Data/cifar-10-batches-py'\n",
    "train_data, train_labels, test_data, test_labels = load_cifar10_data(data_dir)\n",
    "\n",
    "print(\"Training data set : %3d, Test data Set : %3d\" %(train_data.shape[0], test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trl = tf.one_hot(train_labels, 10, 1, 0, -1)\n",
    "train_label = sess.run(trl)\n",
    "tsl = tf.one_hot(test_labels, 10, 1, 0, -1)\n",
    "test_label = sess.run(tsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_input   = train_data.shape[1]*train_data.shape[2]\n",
    "n_output  = 10\n",
    "n_indepth = train_data.shape[3]\n",
    "\n",
    "Ker1size  = 11\n",
    "Ker1depth = 96\n",
    "Ker2size  = 5\n",
    "Ker2depth = 256\n",
    "Ker3size  = 3\n",
    "Ker3depth = 384\n",
    "Ker4size  = 3\n",
    "Ker4depth = 256\n",
    "\n",
    "Map_res = 1024/(4*4*4*4)\n",
    "FC1size   = 1024\n",
    "\n",
    "learning_rate = 0.9\n",
    "\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([Ker1size, Ker1size, n_indepth, Ker1depth], mean=1,stddev=0.1)),\n",
    "    'wc2': tf.Variable(tf.random_normal([Ker2size, Ker2size, Ker1depth, Ker2depth], stddev=0.1)),\n",
    "    'wc3': tf.Variable(tf.random_normal([Ker3size, Ker3size, Ker2depth, Ker3depth], stddev=0.1)),\n",
    "    'wc4': tf.Variable(tf.random_normal([Ker4size, Ker4size, Ker3depth, Ker4depth], stddev=0.1)),    \n",
    "    \n",
    "    'wd1': tf.Variable(tf.random_normal([(int)(Map_res*Ker4depth), FC1size], stddev=0.1)),\n",
    "    'wd2': tf.Variable(tf.random_normal([FC1size, n_output], stddev=0.1))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([Ker1depth], stddev=0.1)),\n",
    "    'bc2': tf.Variable(tf.random_normal([Ker2depth], stddev=0.1)),\n",
    "    'bc3': tf.Variable(tf.random_normal([Ker3depth], stddev=0.1)),\n",
    "    'bc4': tf.Variable(tf.random_normal([Ker4depth], stddev=0.1)),\n",
    "    \n",
    "    'bd1': tf.Variable(tf.random_normal([FC1size], stddev=0.1)),\n",
    "    'bd2': tf.Variable(tf.random_normal([n_output], stddev=0.1))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Network Ready \n"
     ]
    }
   ],
   "source": [
    "def conv_sj(_input, _w, _b, _keepratio):\n",
    "    #CONV LAYER 1\n",
    "    conv1  = tf.nn.conv2d(_input, _w['wc1'], strides=[1,1,1,1], padding='SAME')\n",
    "    mean,var = tf.nn.moments(conv1, [0,1,2])\n",
    "    conv1n = tf.nn.batch_normalization(conv1, mean, var, 0, 1, 0.0001)\n",
    "    conv1a = tf.nn.relu(tf.nn.bias_add(conv1n, _b['bc1']))\n",
    "    pool1  = tf.nn.max_pool(conv1a, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    pool1d = tf.nn.dropout(pool1, _keepratio)\n",
    "    conv1o = pool1d\n",
    "    \n",
    "    #CONV LAYER 2\n",
    "    conv2  = tf.nn.conv2d(conv1o, _w['wc2'], strides=[1,1,1,1], padding='SAME')\n",
    "    mean,var = tf.nn.moments(conv2, [0,1,2])\n",
    "    conv2n = tf.nn.batch_normalization(conv2, mean, var, 0, 1, 0.0001)\n",
    "    conv2a = tf.nn.relu(tf.nn.bias_add(conv2n, _b['bc2']))\n",
    "    pool2  = tf.nn.max_pool(conv2a, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    pool2d = tf.nn.dropout(pool2, _keepratio)\n",
    "    conv2o = pool2d\n",
    "    \n",
    "    #CONV LAYER 3\n",
    "    conv3  = tf.nn.conv2d(conv2o, _w['wc3'], strides=[1,1,1,1], padding='SAME')\n",
    "    mean,var = tf.nn.moments(conv3, [0,1,2])\n",
    "    conv3n = tf.nn.batch_normalization(conv3, mean, var, 0, 1, 0.0001)\n",
    "    conv3a = tf.nn.relu(tf.nn.bias_add(conv3n, _b['bc3']))\n",
    "    pool3  = tf.nn.max_pool(conv3a, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    pool3d = tf.nn.dropout(pool3, _keepratio)\n",
    "    conv3o = pool3d\n",
    "    \n",
    "    #CONV LAYER 4\n",
    "    conv4  = tf.nn.conv2d(conv3o, _w['wc4'], strides=[1,1,1,1], padding='SAME')\n",
    "    mean,var = tf.nn.moments(conv4, [0,1,2])\n",
    "    conv4n = tf.nn.batch_normalization(conv4, mean, var, 0, 1, 0.0001)\n",
    "    conv4a = tf.nn.relu(tf.nn.bias_add(conv4n, _b['bc4']))\n",
    "    pool4  = tf.nn.max_pool(conv4a, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    pool4d = tf.nn.dropout(pool4, _keepratio)\n",
    "    conv4o = pool4d\n",
    "    \n",
    "    #VECTORIZE\n",
    "    dense1 = tf.reshape(conv4o, [-1, _w['wd1'].get_shape().as_list()[0]])\n",
    "    \n",
    "    #FULLY CONNECTED LAYER 1\n",
    "    fc1    = tf.nn.relu(tf.add(tf.matmul(dense1, _w['wd1']), _b['bd1']))\n",
    "    fc1d   = tf.nn.dropout(fc1, _keepratio)\n",
    "    fc1o   = fc1d\n",
    "    \n",
    "    #FULLY CONNECTED LAYER 2\n",
    "    fc2    = tf.nn.relu(tf.add(tf.matmul(fc1o, _w['wd2']), _b['bd2']))\n",
    "    out    = fc2\n",
    "    \n",
    "    #RETURNS\n",
    "    _out = {\n",
    "        'conv1': conv1, 'conv1n': conv1n, 'conv1a': conv1a, 'pool1': pool1, 'pool1d': pool1d, 'conv1o':conv1o,\n",
    "        'conv2': conv2, 'conv2n': conv2n, 'conv2a': conv2a, 'pool2': pool2, 'pool2d': pool2d, 'conv2o':conv2o,       \n",
    "        'conv3': conv3, 'conv3n': conv3n, 'conv3a': conv3a, 'pool3': pool3, 'pool3d': pool3d, 'conv3o':conv3o,\n",
    "        'conv4': conv4, 'conv4n': conv4n, 'conv4a': conv4a, 'pool4': pool4, 'pool4d': pool4d, 'conv4o':conv4o,\n",
    "        'dense1': dense1, 'fc1': fc1, 'fc1d': fc1d, 'fc1o': fc1o, 'fc2': fc2, 'out': out\n",
    "    }\n",
    "    return _out   \n",
    "print(\" Network Ready \")\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE COMPUTATIONAL GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-71-f8e79977d631>:10 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "keepratio = tf.placeholder(tf.float32)\n",
    "\n",
    "pred = conv_sj(x, weights, biases, keepratio)['out']\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred,y))\n",
    "optm = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "corr = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accr = tf.reduce_mean(tf.cast(corr, tf.float32))\n",
    "init = tf.initialize_all_variables()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess.run(init)\n",
    "print(\"initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Session.close of <tensorflow.python.client.session.Session object at 0x7ff0def6efd0>>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape\n",
    "sess.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started\n",
      "epoch: 000/005, cost: 3.0455\n",
      "TR acc : 0.100, TS acc : 0.098\n",
      "epoch: 001/005, cost: 2.3026\n",
      "TR acc : 0.101, TS acc : 0.098\n",
      "epoch: 002/005, cost: 2.3026\n",
      "TR acc : 0.100, TS acc : 0.098\n",
      "epoch: 003/005, cost: 2.3026\n",
      "TR acc : 0.100, TS acc : 0.098\n",
      "epoch: 004/005, cost: 2.3026\n",
      "TR acc : 0.100, TS acc : 0.098\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 5\n",
    "batch_size      = 100\n",
    "display_step    = 1\n",
    "\n",
    "print(\"Optimization started\")\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_iter = int(train_data.shape[0]/batch_size)\n",
    "    \n",
    "    for i in range(total_iter):\n",
    "        randidx = np.random.randint(50000, size=batch_size)\n",
    "        batch_xs = train_data[randidx,:,:,:]\n",
    "        batch_ys = train_label[randidx,:]\n",
    "        \n",
    "        sess.run(optm, feed_dict={x: batch_xs, y: batch_ys, keepratio: 0.5})\n",
    "        avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keepratio:1.})/total_iter\n",
    "        \n",
    "        \n",
    "    if epoch % display_step ==0 or epoch == training_epochs-1:\n",
    "        print(\"epoch: %03d/%03d, cost: %.4f\" %(epoch, training_epochs, avg_cost))\n",
    "        training_acc = sess.run(accr, feed_dict={x: train_data[0:10000,:,:,:], y: train_label[0:10000,:], keepratio:1.})\n",
    "        test_acc     = sess.run(accr, feed_dict={x: test_data[0:5000,:,:,:], y: test_label[0:5000,:], keepratio:1.})\n",
    "        print(\"TR acc : %.3f, TS acc : %.3f\" % (training_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.43556511,  1.36108935,  1.34101105,  1.43881857,  1.12045872,\n",
       "         1.17166495,  1.0675    ,  1.11042464,  1.13888204,  1.34621549,\n",
       "         1.12239218],\n",
       "       [ 1.36114812,  1.34451568,  1.30982232,  1.07686996,  1.1096766 ,\n",
       "         1.44167006,  1.2124238 ,  1.07516694,  0.90495706,  0.98410738,\n",
       "         1.48151314],\n",
       "       [ 0.52257687,  0.50284803,  0.61970228,  0.50736535,  0.84917438,\n",
       "         1.08278418,  0.95618892,  0.9587155 ,  0.91195107,  1.08326447,\n",
       "         1.12626624],\n",
       "       [ 0.69164801,  0.60172874,  0.57764882,  0.55144191,  0.88742298,\n",
       "         1.09382904,  1.14436376,  1.25941956,  1.01933169,  0.92493349,\n",
       "         1.09037006],\n",
       "       [ 1.05796576,  1.03275025,  0.70027667,  0.78522104,  0.60386992,\n",
       "         1.06440282,  1.16064501,  0.81264949,  1.04575765,  1.20180297,\n",
       "         1.05160117],\n",
       "       [ 1.23734665,  1.389817  ,  0.87278873,  0.83719671,  0.51160049,\n",
       "         1.43569088,  1.30859065,  1.09812975,  1.27055585,  1.12793684,\n",
       "         1.39984035],\n",
       "       [ 1.20146596,  1.22178149,  0.90180737,  0.88131469,  0.95995045,\n",
       "         1.19283283,  1.28291905,  0.85835111,  1.09482205,  1.23546028,\n",
       "         1.28381693],\n",
       "       [ 0.98477799,  0.81544077,  0.52392536,  0.44029021,  0.47856325,\n",
       "         0.88922542,  0.58575624,  0.48169076,  0.47851044,  1.00245512,\n",
       "         1.24000657],\n",
       "       [ 0.7658326 ,  0.82167625,  0.57580495,  0.51000881,  0.51438254,\n",
       "         0.42992854,  0.62615722,  0.60478151,  0.73722601,  0.92538476,\n",
       "         1.03371489],\n",
       "       [ 0.60057336,  0.5355193 ,  0.74223447,  0.36949268,  0.56600285,\n",
       "         0.48699731,  0.63916159,  0.71452343,  0.65866017,  0.6828984 ,\n",
       "         0.64614809],\n",
       "       [ 0.77708626,  0.80003661,  0.54354316,  0.43297639,  0.53258634,\n",
       "         0.85835975,  0.57774234,  0.61199594,  0.71958202,  0.68915278,\n",
       "         1.02067077]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=weights['wc1'][:,:,1,1]\n",
    "aout=sess.run(a)\n",
    "aout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
